---
title: Big-O 알고리즘의 성능 분석 방법 
date: '2019-08-17T23:46:37.121Z'
template: 'post'
draft: True
slug: 'algorithm/big-o'
category: 'algorithm'
tags:
  - '자료구조'
  - 'ADT'
description: '알고리즘의 성능 분석 방법에 대해 다룬다.시간복잡도(Time Complexity) 와 공간 복잡도(Space Complexity), Big-O 표기법에 대해 다룬다. 그저 잘 동작하는 자료구조와 알고리즘을 찾는 것이 목적이라면 기능별로 자료구조와 알고리즘을 하나씩 만 알아도 충분하다. 잘 동작하는 것이 1차적으로 중요하지만 "얼마나 성능이 좋냐" 도 중요한 항목이다. 최소 자원으로 최대의 효과를 끌어내는 것, 컴퓨터가 발전해 온 방식이 그렇다. 좋은 성능을 측정하기 위해 자료구조와 알고리즘을 분석하고 평가할 수 있어야 한다. 모든 경우에 항상 우월한 성능을 보이는, 만능 키와 같은 자료구조와 알고리즘은 존재하지 않고 맥락에 따라 좋은 알고리즘이 존재한다. 우선 알고리즘 평가에 필요한 요소들에 대해 알아 보자.'
---

## TLDR;

- 알고리즘의 성능 분석 방법에 대해 다룬다.
- 시간복잡도(Time Complexity) 와 공간 복잡도(Space Complexity), Big-O 표기법에 대해 다룬다. 

## 들어가며 

 그저 잘 동작하는 자료구조와 알고리즘을 찾는 것이 목적이라면 기능별로 자료구조와 알고리즘을 하나씩 만 알아도 충분하다. 잘 동작하는 것이 1차적으로 중요하지만 "얼마나 성능이 좋냐" 도 중요한 항목이다. 최소 자원으로 최대의 효과를 끌어내는 것, 컴퓨터가 발전해 온 방식이 그렇다. 좋은 성능을 측정하기 위해 자료구조와 알고리즘을 분석하고 평가할 수 있어야 한다. 모든 경우에 항상 우월한 성능을 보이는, 만능 키와 같은 자료구조와 알고리즘은 존재하지 않고 맥락에 따라 좋은 알고리즘이 존재한다. 우선 알고리즘 평가에 필요한 요소들에 대해 알아 보자. 

## 시간복잡도(Time Complexity) 와 공간 복잡도(Space Complexity)

알고리즘을 평가하는 할 때 고려하는 2 가지 요소가 있는데, 맥락에 따라 무엇을 우선해야 할지가 바뀐다. 2가지 요소는 다음과 같다. 

> "어떤 알고리즘이 어떠한 상황에서 더 빠르고 또 느리냐?"
>
> "어떤 알고리즘이 어떠한 상황에서 메모리를 적게 쓰고 또 많이 쓰냐?"

이렇듯 하나는 '속도'에 관한 것이고 다른 하나는 '메모리의 사용량'에 관한 것이다. 속도에 해당하는 알고리즘의 수행시간 분석결과를 가리켜 '시간복잡도(Time Complexity)' 라 하고 메모리 사용량에 대한 분석결과를 가리켜 '공간 복잡도(Space Complexity)'라 한다.

사실 메모리를 적게 쓰고 속도도 빨라야 최적의 알고리즘이다. 그런데 일반적으로 알고리즘을 평가할 때 메모리의 사용량보다 실행속도에 초점을 두고 더 중요한 요소로 판단한다. 특정 알고리즘에 대해서 상대적인 우월성을 입증해야 하는 경우에는 메모리의 사용량도 함께 고려가 되지만, 이미 검증이 끝난 알고리즘의 적용을 고려하는 경우에는 속도에 초점을 두어 적합성 여부를 판단한다. 

## 속도는 어떻게 평가하는가?

알고리즘의 속도평가는 단순하지 않다. 처리해야 할 데이터양의 변화에 따른 속도의 증가 및 감소의 정도까지 함께 고려해야하기 때문이다. 이를 위해서 조건을 달리하여 수백 번, 수천 번 실행해가며 시간을 잴 수 없다. 그래서 알고리즘의 수행속도를 평가할 때는 다음과 같은 방식을 취한다. 

> "연산의 횟수를 센다"
>
> "그리고 처리해야 할 데이터의 수 n 에 대한 연산횟수의 함수 T(n) 을 구성한다."

한마디로 연산 횟수를 통해서 알고리즘의 빠르기를 판단하는 것이다. 연산의 횟수가 적야야 빠른 알고리즘이다. 그리고 '데이터의 수 n에 대한 연산횟수의 함수T(n)을 구성한다'는 것은 데이터의 수를 함수에 입력하면 연산의 횟수가 바로 계산이 되는 식을 구성한다는 뜻인데, 이렇듯 식을 구성하는 이유는 다음과 같다. 

> "식을 구성하면 데이터 수의 증가에 따른 연산횟수의 변화 정도를 판단할 수 있다"

즉 알고리즘 별 연산횟수를 함수 T(n)의 형태로 구현하면 아래 그림에서 처럼 그래프를 통해서 데이터 수의 변화에 따른 연산횟수의 변화 정도를 한눈에 파악할 수 있고, 이로 인해 둘 이상의 알고리즘 평가에 용이하다.

![알고리즘의 수행속도 비교](https://user-images.githubusercontent.com/35516239/63205598-c104c280-c0e1-11e9-85e5-04d4b9cf9b6d.png)

그럼 위 그림에서 보이는 것이, 동일한 기능을 제공하는 서로 다른 두 알고리즘의 성능을 비교한 결과라고 가정하자. 이 두 알고리즘의 비교 결과를 나열해 보자.

>"데이터의 수가 적을 땐 알고리즘 B가 더 빠르구나"
>
>"근데 데이터의 수가 좀 늘어나면 알고리즘 A가 훨씬 더 빨라지는데!"

위의 분석결과를 토대로 다음과 같이 판단할 수 있다. 

> "데이터의 수가 적은 경우에는 알고리즘 B를 적용하고, 데이터의 수가 많은 경우에는 알고리즘 A를 적용해야 한다"

위의 판단이 정확할까? 잘못된 판단은 아니다. 나름 합리적인 판단이고 실제로 이렇게 판단하고 적용하는 경우도 있다. 하지만 데이터의 수가 적은 경우, 속도 차가 얼마나 많이날까? 중요한 것은 데이터의 수가 많아짐에 따른 연산회수의 증가 정도에 있다.

> "그렇게 놓고 보면 알고리즘 A가 훨씬 좋은 알고리즘이자나!"

그렇다. 알고리즘 A가 더 좋은 알고리즘이다.

> "그럼 알고리즘 B는 필요가 없구나"

아니다. 대게 A와 같이 안정적인 성능을 보장하는 알고리즘은 B와 같은 성격의 알고리즘에 비해서 구현의 난이도가 높은 편이다. 따라서 데이터의 수가 많지 않고 성능에 덜 민감한 경우라면 구현의 편의를 이유로 B와 같은 알고리즘을 선택하기도 한다. 

> "그럼 알고리즘 분야에 정답이 없는건가? 

정답이 없는 것이 아니라 맥락에 따른 정답이 있다. 따라서 알고리즘의 구현능력에만 관심을 두는 것이 아니라, 맥락적 그리고 종합적 평가를 통해 상황에 맞는 알고리즘을 선택할 수 있는 사고력이 중요하다. 

